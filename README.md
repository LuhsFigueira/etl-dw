# üöÄ Projeto ETL ‚Äì Data Warehouse (MongoDB ‚Üí PostgreSQL)

Este projeto implementa um **pipeline de ETL (Extract, Transform, Load)** respons√°vel por migrar dados operacionais armazenados em **MongoDB** para um **Data Warehouse em PostgreSQL**, utilizando **modelagem dimensional (Star Schema)** para an√°lises anal√≠ticas e relat√≥rios financeiros.

O objetivo √© demonstrar boas pr√°ticas de **Engenharia de Dados**, incluindo:
- Tratamento de dados semi-estruturados (JSON)
- Padroniza√ß√£o e qualidade de dados
- Uso de vari√°veis de ambiente
- Modelagem OLAP

---

## üß± Arquitetura do Projeto

**Fonte (OLTP / NoSQL)**
- MongoDB
  - users
  - products
  - carts

**Destino (OLAP / SQL)**
- PostgreSQL
  - dim_usuario
  - dim_produto
  - fact_transacao

---

## ‚≠ê Modelagem Dimensional

### üîπ Dimens√µes

**dim_usuario**
- user_id
- name
- email
- gender
- birthdate
- city
- state
- country

**dim_produto**
- product_id
- product_name
- category
- brand
- price
- rating
- stock
- barcode
- created_at
- sku


### üîπ Fato

**fact_transacao**
- sale_id
- user_id
- product_id
- date_id
- quantity
- unit_price
- total_price
- discount_pct
- final_price

**Gr√£o da Fato:**
> 1 linha = 1 produto vendido em uma transa√ß√£o

---

## üìÅ Estrutura do Projeto

```text
etl-dw/
‚îú‚îÄ‚îÄ db/
‚îÇ   ‚îú‚îÄ‚îÄ mongo_config.py
‚îÇ   ‚îî‚îÄ‚îÄ postgres_config.py
‚îÇ   sql/
‚îÇ   ‚îú‚îÄ‚îÄ analises.sql
‚îÇ   ‚îî‚îÄ‚îÄ tabelas.sql
‚îú‚îÄ‚îÄ dim_usuario.py
‚îú‚îÄ‚îÄ dim_produto.py
‚îú‚îÄ‚îÄ fact_transacao.py
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ .env
‚îú‚îÄ‚îÄ .gitignore
‚îî‚îÄ‚îÄ README.md
```

---

## üîê Vari√°veis de Ambiente

As credenciais **n√£o ficam no c√≥digo**. Elas s√£o carregadas via `.env`.

### üìÑ Exemplo de `.env`

```env
# MongoDB
MONGO_USER=admin
MONGO_PASSWORD=password123
MONGO_HOST=localhost
MONGO_PORT=27017
MONGO_DB=raw_data
MONGO_AUTH_SOURCE=admin

# PostgreSQL
PG_USER=user_analytics
PG_PASSWORD=password123
PG_HOST=localhost
PG_PORT=5432
PG_DB=analytics_db
```


---

## üì¶ Depend√™ncias

Instale todas as depend√™ncias com:

```bash
python -m pip install -r requirements.txt
```

Conte√∫do do `requirements.txt`:

```text
pandas>=2.1,<3.0
pymongo>=4.6
sqlalchemy>=2.0,<3.0
psycopg2-binary>=2.9
python-dotenv>=1.0
openpyxl>=3.1
```

---
## ‚ñ∂Ô∏è Restaurar o banco PostgreSQL com dados


docker-compose up -d

docker exec -i dest_postgres psql \
  -U user_analytics \
  -d analytics_db < postgres_dump.sql



## ‚ñ∂Ô∏è Como Executar o Pipeline

### 1Ô∏è‚É£ Criar ambiente virtual

```bash
python -m venv venv
source venv/bin/activate   # Linux / Mac
# venv\Scripts\activate   # Windows
```

### 2Ô∏è‚É£ Instalar depend√™ncias

```bash
python -m pip install -r requirements.txt
```

### 3Ô∏è‚É£ Executar ETL

```bash
python dim_usuario.py
python dim_produto.py
python fact_transacao.py
```

---

## üß† Principais Decis√µes T√©cnicas

- Datas normalizadas a partir do **n√≠vel da transa√ß√£o (cart)**
- Convers√£o robusta de m√∫ltiplos formatos de data (ISO, BR, Unix timestamp)
- Dados sens√≠veis removidos
- Uso de **vari√°veis de ambiente**
- Fato com m√©tricas financeiras prontas para BI

---

## üìä Pronto para BI

O Data Warehouse gerado √© compat√≠vel com:
- Power BI
- Tableau
- Looker

Permite an√°lises como:
- Faturamento di√°rio/mensal
- Ticket m√©dio
- Produtos mais vendidos
- Descontos aplicados
- An√°lise por usu√°rio e regi√£o

---

## üë®‚Äçüíª Autor

Projeto desenvolvido como **case t√©cnico de Engenharia de Dados**, com foco em boas pr√°ticas, clareza arquitetural e qualidade de dados.

---


